
mod_h2 - a http/2 modules for apache httpd
==========================================
The mod_h2 Apache httpd module implements the HTTP2 protocol (h2+h2c) on
top of libnghttp2 for httpd 2.4 servers. For a general description, see
the README, installation issues are detailed in INSTALL.

This document is for discussion of the module's internals, current issues
and exploration of ideas.


THE GOALS
---------
The goals of this module can be stated as follows:
- make the full htpp2 standard available in Apache httpd
- provide it as a module on top of httpd 2.4.x
- support deployment on standard unix platforms


HOW IT WORKS
------------
The architecture of this module is heavily inspired by Google's mod_spdy:
The incoming, parallel requests (http2 streams) are dispatched to a thread
pool, responses are collected and multiplexed on the original connection.

The major players in ascii art:

  h2_conn -> h2_session ------> h2_mplx ----> h2_task / h2_worker
  (socket)   (nghttp2_session)            |-> h2_task / h2_worker
                                          |-> h2_task / h2_worker
                                                ...

h2_session: by using nghttp2 API, is doing the http2 frame work, stream
            states, flow control, etc. Sits as connection level filter
            on standard httpd connections. Gets active either by ALPN
            selection or as HTTP/1.1 Upgrade from a request.

h2_mplx:    is a somewhat specialized bucket_brigate. It multiplexes data
            buckets associated with stream IDs in both directions and
            has some specials to reset streams or announce response headers.
            It also performs flow control on the downlink of streams.

h2_task:    having own conn_rec instance, plus in/out filters at connection
            level, is converting http2 streams into http/1.1 requests and
            parses back responses to http2 usable headers and data.


LIFETIMES
---------
For each connection that uses HTTP/2, a new h2_session is created. That lives
as long as all objects it creates: h2_stream and h2_task instances. So, when
closing a h2_session, this waits until all associated h2_streams have
been destroyed. h2_streams will only be destroyed when their h2_task is either
removed from the schedule queue or has terminated.

Insofar, the lifetimes from h2_session/h2_stream have the similar relations as
conn_rec/request_rec with the exception that there can be many simultaneous
h2_streams active per h2_session (and in various worker threads).


THREAD HANDLING
---------------
h2_session is only ever accessed from the thread handling the original
connection. Same for h2_stream instances. The execution of what is necessary
for execution of a h2_stream happens in h2_task. h2_task gets instantiated
in the connection thread, but is the handed to a worker and, apart from
checking its status atomically, not called by any other thread.

The object that shovels the data packages back and forth and is accessed from
multiple threads is h2_mplx. h2_tasks use it to retrieve their input and feed
it their output. h2_mplx blocks h2_tasks when no input is available or
the amount of output queue has reached a certain maximum.


MEMORY HANDLING
---------------
Since the parallelism and thread use of h2_session/h2_stream/h2_task is
different from conn_rec/request_rec, the apr memory pools need to be handled
carefully.


THREAD HANDLING
---------------
There is a nice thread pool in apr-util which even suports priority scheduling.
It would be nice to exchange the h2_worker(s) for this pool, except mod_h2
has the use case that streams can be aborted by the client and the
corresponding task needs to be removed from the schedule without any
blocking wait for a possibly running task to complete. This is not offered
by apr-util.


DISCUSSION / OPEN QUESTIONS
---------------------------
While HTTP2 clients will be happy to have low lags in using the protocol,
httpd owners will notice performance degradations. Early measurements
indicate that for small requests, like the famous gopher tile page
(https://http2.golang.org/gophertiles), requests/s in loadtests show only
50% - 70% of the original HTTP/1.1 + TLS values. These tests were done
with h2load, a nghttp2 client working with multiple threads.

The main causes for this performance penalty seem to be:
- the mod_h2 architecture serializes HTTP2 headers into a HTTP/1.1 request
  and parses back a HTTP/1.1 response into headers and data for the HTTP2
  engine.
  We know currently of no way to directly have httpd processing a request_rec.
  Maybe that can be done with some internal know-how use as temporary
  work around...
- Data copying:
  APR and httpd have wonderful bucket brigades, but mod_h2 is not using them
  to the fullest capabilities. There are questions regarding multi-thread use
  of pools, subpools and brigades that make expert advice needed.
  So, what copying is done?
  INPUT:
    brigade(socket) --> nghttp2 read --> h2_bucket --> brigade(h2_task)
  OUTPUT
    brigade(h2_task) --> h2_bucket --> nghttp2 buffer --> brigade(socket)
  Due to async handling and the capabilities of nghttp2, we have to make
  copies at certain points in the process. Maybe we could avoid one copy
  in the OUTPUT queue, if we get a grip on multi-threaded bucket brigade
  handling...
- MPM MODULES:
  mod_h2 currently works with mpm_worker only. mpm_event currently crashes as
  connection and connection config setup does not yet make the necessary
  incantations for mpm_event to be happy. We think there is no inherent
  problem with running inside mpm_event, since mod_h2 handles pseudo-connection
  in- and output itself, using thread_mutex/cond to block/signal.
  Since mpm_event is standard in most distros nowadays, it would be good to
  get that working.
- MEMORY:
  mod_h2 creates a new pool for every session, subpools for all streams and
  sub-sub-pools for each task. Before destroying streams or the session, running
  tasks are joined. That seems to work stable.
  Using less pools keeps crashing, also the time/thread of pool creation seems
  to play a role. Unless we understand this better, more optimization seems
  difficult.
- THREADS
  The own worker thread pool does not share resources with the mpm worker pools.
  Seems like a module in 2.4 is limited here. Maybe something to discuss in
  future development.


